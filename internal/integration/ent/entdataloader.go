// Code generated by entc, DO NOT EDIT.

package ent

import (
	"context"
	"sync"
	"time"

	"github.com/cliedeman/entdataloader/internal/integration/ent/post"
	"github.com/cliedeman/entdataloader/internal/integration/ent/user"
)

type PostAuthorDataloader struct {
	client *Client
	ctx    context.Context
	wait   time.Duration
	// maxBatch int

	filter func(*UserQuery) *UserQuery
	batch  *PostAuthorDataloaderBatch

	// mutex to prevent races
	mu sync.Mutex
}

type PostAuthorDataloaderOption func(*PostAuthorDataloader)

func PostAuthorDataloaderWithWait(wait time.Duration) PostAuthorDataloaderOption {
	return func(l *PostAuthorDataloader) {
		l.wait = wait
	}
}

func PostAuthorDataloaderWithFilter(filter func(*UserQuery) *UserQuery) PostAuthorDataloaderOption {
	return func(l *PostAuthorDataloader) {
		l.filter = filter
	}
}

func NewPostAuthorDataloader(ctx context.Context, client *Client, opts ...PostAuthorDataloaderOption) *PostAuthorDataloader {
	l := &PostAuthorDataloader{
		ctx:    ctx,
		client: client,
		wait:   time.Millisecond * 500,
	}
	for _, opt := range opts {
		opt(l)
	}
	return l
}

// TODO: make private
type PostAuthorDataloaderBatch struct {
	keys    map[int]interface{}
	data    []*User
	error   error
	closing bool
	done    chan struct{}
}

func (l *PostAuthorDataloader) Load(key int) (*User, error) {
	return l.LoadThunk(key)()
}

func (l *PostAuthorDataloader) LoadThunk(key int) func() (*User, error) {
	l.mu.Lock()
	if l.batch == nil {
		l.batch = &PostAuthorDataloaderBatch{
			done: make(chan struct{}),
			keys: make(map[int]interface{}),
		}
		go l.batch.startTimer(l)
	}
	l.batch.keys[key] = nil
	batch := l.batch
	l.mu.Unlock()

	return func() (*User, error) {
		<-batch.done
		if batch.error != nil {
			return nil, batch.error
		}
		for _, d := range batch.data {
			if d.ID == key {
				return d, nil
			}
		}
		return nil, nil
	}
}

func (b *PostAuthorDataloaderBatch) startTimer(l *PostAuthorDataloader) {
	time.Sleep(l.wait)
	l.mu.Lock()

	// we must have hit a batch limit and are already finalizing this batch
	if b.closing {
		l.mu.Unlock()
		return
	}

	l.batch = nil
	l.mu.Unlock()

	b.end(l)
}

func (b *PostAuthorDataloaderBatch) end(l *PostAuthorDataloader) {
	var ids []int
	for id := range b.keys {
		ids = append(ids, id)
	}
	q := l.client.User.Query().
		Where(user.IDIn(ids...))
	if l.filter != nil {
		q = l.filter(q)
	}
	b.data, b.error = q.All(l.ctx)
	close(b.done)
}

type UserPostsDataloader struct {
	client *Client
	ctx    context.Context
	wait   time.Duration
	// maxBatch int

	filter func(*PostQuery) *PostQuery
	batch  *UserPostsDataloaderBatch

	// mutex to prevent races
	mu sync.Mutex
}

type UserPostsDataloaderOption func(*UserPostsDataloader)

func UserPostsDataloaderWithWait(wait time.Duration) UserPostsDataloaderOption {
	return func(l *UserPostsDataloader) {
		l.wait = wait
	}
}

func UserPostsDataloaderWithFilter(filter func(*PostQuery) *PostQuery) UserPostsDataloaderOption {
	return func(l *UserPostsDataloader) {
		l.filter = filter
	}
}

func NewUserPostsDataloader(ctx context.Context, client *Client, opts ...UserPostsDataloaderOption) *UserPostsDataloader {
	l := &UserPostsDataloader{
		ctx:    ctx,
		client: client,
		wait:   time.Millisecond * 500,
	}
	for _, opt := range opts {
		opt(l)
	}
	return l
}

// TODO: make private
type UserPostsDataloaderBatch struct {
	keys    map[int]interface{}
	data    []*Post
	error   error
	closing bool
	done    chan struct{}
}

func (l *UserPostsDataloader) Load(key int) ([]*Post, error) {
	return l.LoadThunk(key)()
}

func (l *UserPostsDataloader) LoadThunk(key int) func() ([]*Post, error) {
	l.mu.Lock()
	if l.batch == nil {
		l.batch = &UserPostsDataloaderBatch{
			done: make(chan struct{}),
			keys: make(map[int]interface{}),
		}
		go l.batch.startTimer(l)
	}
	l.batch.keys[key] = nil
	batch := l.batch
	l.mu.Unlock()

	return func() ([]*Post, error) {
		<-batch.done
		if batch.error != nil {
			return nil, batch.error
		}
		var data []*Post
		var err error
		for _, d := range batch.data {
			if d.AuthorID == key {
				data = append(data, d)
			}
		}
		return data, err
	}
}

func (b *UserPostsDataloaderBatch) startTimer(l *UserPostsDataloader) {
	time.Sleep(l.wait)
	l.mu.Lock()

	// we must have hit a batch limit and are already finalizing this batch
	if b.closing {
		l.mu.Unlock()
		return
	}

	l.batch = nil
	l.mu.Unlock()

	b.end(l)
}

func (b *UserPostsDataloaderBatch) end(l *UserPostsDataloader) {
	var ids []int
	for id := range b.keys {
		ids = append(ids, id)
	}
	q := l.client.Post.Query().
		Where(post.AuthorIDIn(ids...))
	if l.filter != nil {
		q = l.filter(q)
	}
	b.data, b.error = q.All(l.ctx)
	close(b.done)
}
